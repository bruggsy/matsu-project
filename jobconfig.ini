### Python requires section headings and Java ignores them, so we'll just have one section for everything
[DEFAULT]

### Java Virtual Machine
lib.jvm = /usr/local/java/jre/lib/amd64/server/libjvm.so

### Accumulo interface parameters
accumulo.interface = /opt/matsuAccumuloInterface.jar
accumulo.db_name = matsu
accumulo.zookeeper_list = 
accumulo.user_name = 
accumulo.password = 
accumulo.table_name = MatsuLevel2Tiles3
accumulo.points_table_name = MatsuLevel2Clusters
accumulo.polygons_table_name = MatsuLevel2Polygons

### Hadoop executable
exe.hadoop = /opt/hadoop/bin/hadoop

### Tiling map-reduce job configuration
preprocess.matsuSequenceFileInterface = /opt/matsuSequenceFileInterface.jar
mapper.zoomDepthNarrowest = 10
mapper.tileLongitudePixels = 512
mapper.tileLatitudePixels = 256
mapper.numberOfLatitudeSections = 1
mapper.splineOrder = 3
mapper.useSequenceFiles = true
mapper.outgoingBandRestriction = ["B05", "B04", "B02", "CLOUDS", "LAND", "WATER"]
mapper.modules = ["flood_detection_R.py"]
mapper.configuration = [{"layer": "RGB", "bands": ["B05", "B04", "B02"], "outputType": "RGB", "minRadiance": 0.0, "maxRadiance": "sun"}, {"layer": "flood", "bands": ["CLOUDS", "LAND", "WATER"], "outputType": "RGB", "minRadiance": 0.0, "maxRadiance": 1.0}]
mapper.outputToAccumulo = true
mapper.outputToLocalDirectory = false
mapper.outputDirectoryName = /tmp/map-reduce
mapper.outputToStdOut = false
